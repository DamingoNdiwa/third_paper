@inproceedings{NIPS2013_af21d0c9,
  title = {Sinkhorn Distances: {{Lightspeed}} Computation of Optimal Transport},
  booktitle = {{Advances in Neural Information Processing Systems}},
  author = {Cuturi, Marco},
  editor = {Burges, C.J. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K.Q.},
  year = {2013},
  volume = {26},
  url = {https://proceedings.neurips.cc/paper_files/paper/2013/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf},
  publisher = {{Curran Associates, Inc.}}}


@article{cuturi2022optimal,
  title={{Optimal Transport Tools} ({OTT}): A {JAX} Toolbox for all things {Wasserstein}},
  author={Cuturi, Marco and Meng-Papaxanthos, Laetitia and Tian, Yingtao and Bunne, Charlotte and
          Davis, Geoff and Teboul, Olivier},
  journal={arXiv preprint arXiv:2201.12324},
  year={2022}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{vallender_calculation_1974,
	title = {Calculation of the {Wasserstein} {Distance} {Between} {Probability} {Distributions} on the {Line}},
	volume = {18},
	issn = {0040-585X},
	url = {https://epubs.siam.org/doi/10.1137/1118101},
	doi = {10.1137/1118101},
	number = {4},
	urldate = {2024-07-12},
	journal = {Theory of Probability \& Its Applications},
	author = {Vallender, S. S.},
	month = sep,
	year = {1974},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {784--786},
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@article{ghorbanzadeh_method_2014,
	title = {A {Method} to {Simulate} the {Skew} {Normal} {Distribution}},
	volume = {05},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2152-7385, 2152-7393},
	doi = {10.4236/am.2014.513201},
	number = {13},
	urldate = {2024-07-12},
	journal = {Applied Mathematics},
	author = {Ghorbanzadeh, Dariush and Jaupi, Luan and Durand, Philippe},
	year = {2014},
	pages = {2073--2076},
}


@software{deepmind2020jax,
  title = {The {D}eep{M}ind {JAX} {E}cosystem},
  author = {DeepMind and Babuschkin, Igor and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and Dedieu, Antoine and Fantacci, Claudio and Godwin, Jonathan and Jones, Chris and Hemsley, Ross and Hennigan, Tom and Hessel, Matteo and Hou, Shaobo and Kapturowski, Steven and Keck, Thomas and Kemaev, Iurii and King, Michael and Kunesch, Markus and Martens, Lena and Merzic, Hamza and Mikulik, Vladimir and Norman, Tamara and Papamakarios, George and Quan, John and Ring, Roman and Ruiz, Francisco and Sanchez, Alvaro and Sartran, Laurent and Schneider, Rosalia and Sezener, Eren and Spencer, Stephen and Srinivasan, Srivatsan and Stanojevi\'{c}, Milo\v{s} and Stokowiec, Wojciech and Wang, Luyu and Zhou, Guangyao and Viola, Fabio},
  url = {http://github.com/deepmind},
  year = {2020},
}

@article{dillonTensorFlowDistributions2017,
  title = {{{TensorFlow Distributions}}},
  author = {Dillon, Joshua V. and Langmore, Ian and Tran, Dustin and Brevdo, Eugene and Vasudevan, Srinivas and Moore, Dave and Patton, Brian and Alemi, Alex and Hoffman, Matt and Saurous, Rif A.},
  year = {2017},
  journal = {{arXiv}},
  doi = {10.48550/ARXIV.1711.10604},
  urldate = {2023-10-01},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),Programming Languages (cs.PL)}
}

@article{hoffman2014,
  title = {The {{No-U-Turn}} Sampler: Adaptively Setting Path Lengths in {{Hamiltonian Monte Carlo}}.},
  author = {Hoffman, Matthew D and Gelman, Andrew},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {15},
  number = {1},
  pages = {1593--1623}
}

@article{friel2008marginal,
  title = {Marginal {{Likelihood Estimation}} via {{Power Posteriors}}},
  author = {Friel, N. and Pettitt, A. N.},
  year = {2008},
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {70},
  number = {3},
  pages = {589--607},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.1467-9868.2007.00650.x},
  urldate = {2023-08-07},
  abstract = {Summary             Model choice plays an increasingly important role in statistics. From a Bayesian perspective a crucial goal is to compute the marginal likelihood of the data for a given model. However, this is typically a difficult task since it amounts to integrating over all model parameters. The aim of the paper is to illustrate how this may be achieved by using ideas from thermodynamic integration or path sampling. We show how the marginal likelihood can be computed via Markov chain Monte Carlo methods on modified posterior distributions for each model. This then allows Bayes factors or posterior model probabilities to be calculated. We show that this approach requires very little tuning and is straightforward to implement. The new method is illustrated in a variety of challenging statistical settings.},
  langid = {english}
}

@article{ohaganPropertiesIntrinsicFractional1997,
  title = {Properties of Intrinsic and Fractional {{Bayes}} Factors},
  author = {O’Hagan, Anthony.},
  year = {1997},
  journal = {Test},
  shortjournal = {Test},
  volume = {6},
  number = {1},
  pages = {101--118},
  issn = {1133-0686, 1863-8260},
  doi = {10.1007/BF02564428},
  urldate = {2023-08-01},
    publisher={Springer},
  langid = {english}
}


@article{ghaderinezhadWassersteinImpactMeasure2022,
  title = {The {{Wasserstein Impact Measure}} ({{WIM}}): {{A}} Practical Tool for Quantifying Prior Impact in {{Bayesian}} Statistics},
  author = {Ghaderinezhad, Fatemeh and Ley, Christophe and Serrien, Ben},
  year = {2022},
  journal = {Computational Statistics \& Data Analysis},
  shortjournal = {Computational Statistics \& Data Analysis},
  volume = {174},
  pages = {107352},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2021.107352},
  abstract = {The prior distribution is a crucial building block in Bayesian analysis, and its choice will impact the subsequent inference. It is therefore important to have a convenient way to quantify this impact, as such a measure of prior impact will help to choose between two or more priors in a given situation. To this end a new approach, the Wasserstein Impact Measure (WIM), is introduced. In three simulated scenarios, the WIM is compared to two competitor prior impact measures from the literature, and its versatility is illustrated via two real datasets.},
  keywords = {Effective sample size,Neutrality,Prior distribution,Vallender formula,Wasserstein distance}
}

@article{azzalini2023,
  title={R package ‘sn’},
  author={Azzalini, Adelchi},
  journal={The Skew-Normal and Related Distributions Such as the Skew-t and
the SUN},
  year={2023},
  url={http://azzalini.stat.unipd.it/SN/}
}


@article{azzaliniClassD1985,
  title = {A {{Class}} of {{Distributions Which Includes}} the {{Normal Ones}}},
  author = {Azzalini, A.},
  year = {1985},
  journal = {Scandinavian Journal of Statistics},
  volume = {12},
  number = {2},
  eprint = {4615982},
  eprinttype = {jstor},
  pages = {171--178},
  publisher = {{[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]}},
  issn = {03036898, 14679469},
  url = {http://www.jstor.org/stable/4615982},
  abstract = {[A new class of density functions depending on a shape parameter λ is introduced, such that λ=0 corresponds to the standard normal density. The properties of this class of density functions are studied.]}
}

